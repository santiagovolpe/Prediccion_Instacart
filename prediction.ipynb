{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "412d76d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54676393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reemplazar con la dirección del archivo descargado\n",
    "products = pd.read_csv('C:\\\\Users\\\\Usuario\\\\Downloads\\\\archive\\\\products.csv') \n",
    "train_orders = pd.read_csv('C:\\\\Users\\\\Usuario\\\\Downloads\\\\archive\\\\order_products__train.csv', nrows = 500000)\n",
    "# las ordenes prior tienen mas de 30 millones de filas, para reducir intentamos con 1 millon\n",
    "prior_orders = pd.read_csv('C:\\\\Users\\\\Usuario\\\\Downloads\\\\archive\\\\order_products__prior.csv', nrows= 3000000) \n",
    "orders = pd.read_csv('C:\\\\Users\\\\Usuario\\\\Downloads\\\\archive\\\\orders.csv')\n",
    "#aisles = pd.read_csv('C:\\\\Users\\\\Usuario\\\\Downloads\\\\archive\\\\aisles.csv')\n",
    "#departments = pd.read_csv('C:\\\\Users\\\\Usuario\\\\Downloads\\\\archive\\\\departments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08e381cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['order_id', 'user_id', 'eval_set', 'order_number', 'order_dow',\n",
      "       'order_hour_of_day', 'days_since_prior_order'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(orders.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0732ef45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['order_id', 'user_id', 'eval_set', 'order_number', 'order_dow',\n",
      "       'order_hour_of_day', 'days_since_prior_order'],\n",
      "      dtype='object')\n",
      "Index(['order_id', 'product_id', 'add_to_cart_order', 'reordered'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(orders.columns)\n",
    "print(prior_orders.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2020c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_past = orders[orders[\"eval_set\"] == \"prior\"]\n",
    "orders_past = orders_past.drop([\"eval_set\"], axis=1)\n",
    "# juntamos toda la información de cada orden en un data frame\n",
    "prior = prior_orders.merge(orders_past, on=\"order_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3cc6236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# usamos estas funciones para ahorrar espacio\n",
    "# cuando no necesitamos más un data frame, lo borramos\n",
    "del prior_orders, orders_past\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed45ea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_present = orders[orders[\"eval_set\"]== \"train\"]\n",
    "orders_present = orders_present.drop([\"eval_set\"], axis=1)\n",
    "present = train_orders.merge(orders_present, on=\"order_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b029d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_orders, orders, orders_present\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91a32b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vemos los usuarios que tenemos en comun entre las ordenes pasada y las actuales\n",
    "common_users = set(present['user_id']).intersection(set(prior['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b582f3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nos quedamos solo con esos usuarios (solo usar si no se quiere intentar predecir en usuarios nuevos)\n",
    "present = present[present['user_id'].isin(common_users)]\n",
    "prior = prior[prior['user_id'].isin(common_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c225220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28976\n",
      "28976\n",
      "28976\n"
     ]
    }
   ],
   "source": [
    "print(len((present['user_id']).unique()))\n",
    "print(len((prior['user_id']).unique()))\n",
    "print(len(common_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0922b0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(310377, 9)\n",
      "(689200, 9)\n"
     ]
    }
   ],
   "source": [
    "# para saber las dimensiones de nuestro data frame \n",
    "# habrán cambiado si es que nos quedamos con los usuarios en común solamente\n",
    "print(present.shape)\n",
    "print(prior.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfb73b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Count how many times each user-product pair appears\n",
    "user_product_counts = prior.groupby(['user_id', 'product_id']).size()\n",
    "\n",
    "# Identify first-time purchases (should be where count == 1 and reordered == 0)\n",
    "first_time_purchases = prior[(prior['reordered'] == 0)]\n",
    "\n",
    "# See if there are any reordered = 0 where the user has bought the product before\n",
    "# (i.e., check for any inconsistencies)\n",
    "reordered_zero_duplicates = first_time_purchases.duplicated(subset=['user_id', 'product_id'], keep=False)\n",
    "\n",
    "print(reordered_zero_duplicates.any())  # Should be False if reordered=0 means first-time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ee61eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estas columnas podrían ser muy influyentes\n",
    "# la mayoría de nuestros negativos serán combinaciones de usuario-producto no existentes previamente\n",
    "\n",
    "present = present.drop('reordered', axis = 1)\n",
    "prior = prior.drop('reordered', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9d56413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['order_id', 'product_id', 'add_to_cart_order', 'user_id',\n",
      "       'order_number', 'order_dow', 'order_hour_of_day',\n",
      "       'days_since_prior_order'],\n",
      "      dtype='object')\n",
      "Index(['order_id', 'product_id', 'add_to_cart_order', 'user_id',\n",
      "       'order_number', 'order_dow', 'order_hour_of_day',\n",
      "       'days_since_prior_order'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(present.columns)\n",
    "print(prior.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b91e664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average unique products per user: 19.09224875759249\n"
     ]
    }
   ],
   "source": [
    "unique_products_per_user = prior.groupby('user_id')['product_id'].nunique()\n",
    "\n",
    "# Compute the average number of unique products per user\n",
    "average_unique_products = unique_products_per_user.mean()\n",
    "\n",
    "print(\"Average unique products per user:\", average_unique_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a83565f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average orders products per user: 2.3674765323025952\n"
     ]
    }
   ],
   "source": [
    "unique_orders_per_user = prior.groupby('user_id')['order_id'].nunique()\n",
    "\n",
    "# Compute the average number of unique products per user\n",
    "average_unique_orders = unique_orders_per_user.mean()\n",
    "\n",
    "print(\"Average orders products per user:\", average_unique_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4be8388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_negatives_per_order(orders_df, all_products, n_neg):\n",
    "    user_to_products = orders_df.groupby('user_id')['product_id'].apply(set).to_dict()\n",
    "\n",
    "    # Get one context row per order\n",
    "    order_context = orders_df.drop_duplicates('order_id').set_index('order_id')[\n",
    "        ['user_id', 'order_hour_of_day', 'order_dow', 'add_to_cart_order', 'days_since_prior_order']\n",
    "    ].to_dict('index')\n",
    "\n",
    "    negatives = []\n",
    "\n",
    "    for order_id, context in order_context.items():\n",
    "        user = context['user_id']\n",
    "        bought_prods = user_to_products[user]\n",
    "        candidates = list(all_products - bought_prods)\n",
    "        if not candidates:\n",
    "            continue\n",
    "        sampled = np.random.choice(candidates, size=min(n_neg, len(candidates)), replace=False)\n",
    "        for prod in sampled:\n",
    "            negatives.append({\n",
    "                'order_id': order_id,\n",
    "                'product_id': prod,\n",
    "                'add_to_cart_order': context['add_to_cart_order'],\n",
    "                'user_id': user,\n",
    "                'order_dow': context['order_dow'],\n",
    "                'order_hour_of_day': context['order_hour_of_day'],\n",
    "                'days_since_prior_order': context['days_since_prior_order'],\n",
    "                'label': 0\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d85aa589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark positive examples\n",
    "positive = prior\n",
    "positive['label'] = 1\n",
    "pos_df = present\n",
    "pos_df['label'] = 1\n",
    "\n",
    "# All products in catalog\n",
    "all_products = set(products['product_id'].unique())\n",
    "\n",
    "# Generate negatives\n",
    "negative = sample_negatives_per_order(prior, all_products, n_neg=5)\n",
    "neg_df = sample_negatives_per_order(present, all_products, n_neg=5)\n",
    "\n",
    "# Combine positive and negative samples\n",
    "combined = pd.concat([positive, negative], ignore_index=True)\n",
    "comb_df = pd.concat([pos_df, neg_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46d11ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del pos_df, products, neg_df, present, positive, negative\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08d61231",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Product features\n",
    "product_feats = prior.groupby('product_id').agg(\n",
    "    prod_total_orders=('order_id', 'count'),\n",
    "    prod_common_cart_position=('add_to_cart_order', lambda x: x.mode().iloc[0]),\n",
    "    prod_common_hour=('order_hour_of_day', lambda x: x.mode().iloc[0]),\n",
    "    prod_avg_hour=('order_hour_of_day', 'mean'),\n",
    "    prod_std_hour=('order_hour_of_day', 'std'),\n",
    "    prod_common_day=('order_dow', lambda x: x.mode().iloc[0])\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93d3e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features de interacciones entre usuario y producto\n",
    "user_prod_feats = prior.groupby(['user_id', 'product_id']).agg(\n",
    "    most_common_day=('order_dow', lambda x: x.mode().iloc[0]),\n",
    "    common_hour = ('order_hour_of_day', lambda x: x.mode().iloc[0]),\n",
    "    avg_hour = ('order_hour_of_day', 'mean'),\n",
    "    std_hour = ('order_hour_of_day', 'std'),\n",
    "    order_count=('order_id', 'count'),\n",
    "    common_cart_pos=('add_to_cart_order', lambda x: x.mode().iloc[0]),\n",
    "    avg_days_between_orders=('days_since_prior_order', 'mean'),\n",
    "    std_days_between_orders=('days_since_prior_order', 'std')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11e8d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df = comb_df.merge(user_prod_feats, on=['user_id', 'product_id'], how='left')\n",
    "comb_df = comb_df.merge(product_feats, on='product_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd9ee5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined.merge(user_prod_feats, on=['user_id', 'product_id'], how='left')\n",
    "combined = combined.merge(product_feats, on='product_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8edb6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del user_prod_feats, product_feats\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f5396df",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51b9d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.fillna(0, inplace=True)  # reemplazar con 0 los valores vacíos donde nunca hubo tal combinación de usuario y producto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e50c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos nuevas features que dan una nota en base a que tan similares son \n",
    "# las características de ordenes pasadas a las características de las actuales\n",
    "\n",
    "# features de usuario-producto\n",
    "comb_df['match_common_hour'] = abs(comb_df['order_hour_of_day'] - comb_df['common_hour']).astype(int)\n",
    "comb_df['match_days_between'] = abs(comb_df['days_since_prior_order'] - comb_df['avg_days_between_orders']).astype(int)\n",
    "comb_df['within_days_std'] = (\n",
    "    (comb_df['days_since_prior_order'] >= comb_df['avg_days_between_orders'] - comb_df['std_days_between_orders']) &\n",
    "    (comb_df['days_since_prior_order'] <= comb_df['avg_days_between_orders'] + comb_df['std_days_between_orders'])\n",
    ").astype(int)\n",
    "comb_df['match_most_common_day'] = abs(comb_df['order_dow'] - comb_df['most_common_day']).astype(int)\n",
    "comb_df['match_common_cart_pos'] = abs(comb_df['add_to_cart_order'] - comb_df['common_cart_pos']).astype(int)\n",
    "comb_df['match_avg_hour'] = abs(comb_df['order_hour_of_day'] - comb_df['avg_hour']).astype(int)\n",
    "comb_df['within_hour_std'] = (\n",
    "    (comb_df['order_hour_of_day'] >= comb_df['avg_hour'] - comb_df['std_hour']) &\n",
    "    (comb_df['order_hour_of_day'] <= comb_df['avg_hour'] + comb_df['std_hour'])\n",
    ").astype(int)\n",
    "comb_df['user_strength'] = comb_df['order_count'] / comb_df['order_count'].max()\n",
    "\n",
    "\n",
    "# features específicas al producto\n",
    "comb_df['match_prod_common_cart_pos'] = abs(comb_df['add_to_cart_order'] - comb_df['prod_common_cart_position']).astype(int)\n",
    "comb_df['match_prod_common_hour'] = abs(comb_df['order_hour_of_day'] - comb_df['prod_common_hour']).astype(int)\n",
    "comb_df['match_prod_avg_hour'] = abs(comb_df['order_hour_of_day'] - comb_df['prod_avg_hour']).astype(int)\n",
    "comb_df['match_prod_common_day'] = abs(comb_df['order_dow'] - comb_df['prod_common_day']).astype(int)\n",
    "comb_df['within_prod_hour_std'] = (\n",
    "    (comb_df['order_hour_of_day'] >= comb_df['prod_avg_hour'] - comb_df['prod_std_hour']) &\n",
    "    (comb_df['order_hour_of_day'] <= comb_df['prod_avg_hour'] + comb_df['prod_std_hour'])\n",
    ").astype(int)\n",
    "comb_df['product_strength'] = comb_df['prod_total_orders'] / comb_df['prod_total_orders'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92e0c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos nuevas features que dan una nota en base a que tan similares son \n",
    "# las características de ordenes pasadas a las características de las actuales\n",
    "\n",
    "# features de usuario-producto\n",
    "combined['match_common_hour'] = abs(combined['order_hour_of_day'] - combined['common_hour']).astype(int)\n",
    "combined['match_days_between'] = abs(combined['days_since_prior_order'] - combined['avg_days_between_orders']).astype(int)\n",
    "combined['within_days_std'] = (\n",
    "    (combined['days_since_prior_order'] >= combined['avg_days_between_orders'] - combined['std_days_between_orders']) &\n",
    "    (combined['days_since_prior_order'] <= combined['avg_days_between_orders'] + combined['std_days_between_orders'])\n",
    ").astype(int)\n",
    "combined['match_most_common_day'] = abs(combined['order_dow'] - combined['most_common_day']).astype(int)\n",
    "combined['match_common_cart_pos'] = abs(combined['add_to_cart_order'] - combined['common_cart_pos']).astype(int)\n",
    "combined['match_avg_hour'] = abs(combined['order_hour_of_day'] - combined['avg_hour']).astype(int)\n",
    "combined['within_hour_std'] = (\n",
    "    (combined['order_hour_of_day'] >= combined['avg_hour'] - combined['std_hour']) &\n",
    "    (combined['order_hour_of_day'] <= combined['avg_hour'] + combined['std_hour'])\n",
    ").astype(int)\n",
    "combined['user_strength'] = combined['order_count'] / combined['order_count'].max()\n",
    "\n",
    "\n",
    "# features específicas al producto\n",
    "combined['match_prod_common_cart_pos'] = abs(combined['add_to_cart_order'] - combined['prod_common_cart_position']).astype(int)\n",
    "combined['match_prod_common_hour'] = abs(combined['order_hour_of_day'] - combined['prod_common_hour']).astype(int)\n",
    "combined['match_prod_avg_hour'] = abs(combined['order_hour_of_day'] - combined['prod_avg_hour']).astype(int)\n",
    "combined['match_prod_common_day'] = abs(combined['order_dow'] - combined['prod_common_day']).astype(int)\n",
    "combined['within_prod_hour_std'] = (\n",
    "    (combined['order_hour_of_day'] >= combined['prod_avg_hour'] - combined['prod_std_hour']) &\n",
    "    (combined['order_hour_of_day'] <= combined['prod_avg_hour'] + combined['prod_std_hour'])\n",
    ").astype(int)\n",
    "combined['product_strength'] = combined['prod_total_orders'] / combined['prod_total_orders'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4787dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== DataFrame: prior =====\n",
      "Shape: (689200, 9)\n",
      "Memory usage: 52.58 MB\n",
      "\n",
      "===== DataFrame: first_time_purchases =====\n",
      "Shape: (281995, 9)\n",
      "Memory usage: 21.51 MB\n",
      "\n",
      "===== DataFrame: combined =====\n",
      "Shape: (1032200, 37)\n",
      "Memory usage: 291.38 MB\n",
      "\n",
      "===== DataFrame: comb_df =====\n",
      "Shape: (455257, 37)\n",
      "Memory usage: 128.51 MB\n"
     ]
    }
   ],
   "source": [
    "# usar para ver que dataframes están en la memoria en el momento, su peso y sus dimensiones\n",
    "# en este punto solo se necesita df\n",
    "for name, obj in globals().items():\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        print(f\"\\n===== DataFrame: {name} =====\")\n",
    "        print(f\"Shape: {obj.shape}\")\n",
    "        print(f\"Memory usage: {obj.memory_usage().sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3949c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['order_id', 'product_id', 'add_to_cart_order', 'user_id',\n",
      "       'order_number', 'order_dow', 'order_hour_of_day',\n",
      "       'days_since_prior_order', 'label', 'most_common_day', 'common_hour',\n",
      "       'avg_hour', 'std_hour', 'order_count', 'common_cart_pos',\n",
      "       'avg_days_between_orders', 'std_days_between_orders',\n",
      "       'prod_total_orders', 'prod_common_cart_position', 'prod_common_hour',\n",
      "       'prod_avg_hour', 'prod_std_hour', 'prod_common_day',\n",
      "       'match_common_hour', 'match_days_between', 'within_days_std',\n",
      "       'match_most_common_day', 'match_common_cart_pos', 'match_avg_hour',\n",
      "       'within_hour_std', 'user_strength', 'match_prod_common_cart_pos',\n",
      "       'match_prod_common_hour', 'match_prod_avg_hour',\n",
      "       'match_prod_common_day', 'within_prod_hour_std', 'product_strength'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(comb_df.columns) # vemos las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b183bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "752"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quitamos todas las columnas menos las que dan un puntaje de similitud\n",
    "train_df = comb_df.drop(['order_id', 'add_to_cart_order', 'order_dow', 'order_hour_of_day',\n",
    "       'days_since_prior_order', 'most_common_day', 'common_hour',\n",
    "       'avg_hour', 'std_hour', 'order_count', 'common_cart_pos',\n",
    "       'avg_days_between_orders', 'std_days_between_orders', 'prod_total_orders',\n",
    "       'prod_common_cart_position', 'prod_common_hour', 'prod_avg_hour',\n",
    "       'prod_std_hour', 'prod_common_day', 'order_number'], axis = 1)\n",
    "del comb_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "047a8f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = combined.drop(['order_id', 'add_to_cart_order', 'order_dow', 'order_hour_of_day',\n",
    "       'days_since_prior_order', 'most_common_day', 'common_hour',\n",
    "       'avg_hour', 'std_hour', 'order_count', 'common_cart_pos',\n",
    "       'avg_days_between_orders', 'std_days_between_orders', 'prod_total_orders',\n",
    "       'prod_common_cart_position', 'prod_common_hour', 'prod_avg_hour',\n",
    "       'prod_std_hour', 'prod_common_day', 'order_number'], axis = 1)\n",
    "del combined\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff1f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcd8df58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del first_time_purchases\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49349160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# si uno quiere que solo tomando en cuenta las características del producto\n",
    "#training_df = training_df.drop(['match_common_hour',\n",
    "#       'match_days_between', 'within_days_std', 'match_most_common_day',\n",
    "#       'match_common_cart_pos', 'match_avg_hour', 'within_hour_std'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cba50b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 40 rounds\n",
      "[10]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@5: 0.999988\tvalid_0's ndcg@10: 0.999984\n",
      "[20]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n",
      "[30]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n",
      "[40]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@5: 0.999993\tvalid_0's ndcg@10: 0.999994\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "meta_train = training_df[['user_id', 'product_id']].copy()\n",
    "features = [col for col in training_df.columns if col not in ['product_id', 'label']]\n",
    "X_train = training_df[features]\n",
    "y_train = training_df['label']\n",
    "\n",
    "meta_val = train_df[['user_id', 'product_id']].copy()\n",
    "feats = [col for col in train_df.columns if col not in ['product_id', 'label']]\n",
    "X_val = train_df[feats]\n",
    "y_val = train_df['label']\n",
    "\n",
    "\n",
    "# Group arrays: how many rows per user\n",
    "train_groups = meta_train.groupby('user_id').size().tolist()\n",
    "val_groups = meta_val.groupby('user_id').size().tolist()\n",
    "\n",
    "# Create LightGBM Datasets\n",
    "train_data = lgb.Dataset(X_train, label=y_train, group=train_groups)\n",
    "val_data = lgb.Dataset(X_val, label=y_val, group=val_groups)\n",
    "\n",
    "# LightGBM ranking parameters\n",
    "params = {\n",
    "    'objective': 'lambdarank',\n",
    "    'metric': 'ndcg',  # Or 'map' if you prefer\n",
    "    'boosting_type': 'gbdt',\n",
    "    'verbosity': -1,\n",
    "    'num_leaves': 63,\n",
    "    'learning_rate': 0.05,\n",
    "    'ndcg_eval_at': [1, 3, 5, 10]  # Common NDCG cutoff values\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[val_data],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=40),\n",
    "        lgb.log_evaluation(period=10)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe494fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_14376\\4280188630.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val['pred_score'] = model.predict(X_val[feats])\n"
     ]
    }
   ],
   "source": [
    "X_val['pred_score'] = model.predict(X_val[feats]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e206e9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_val.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31bce54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean NDCG@10: 0.8186\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "# Let’s assume: \n",
    "# - X_val has the same features you used for training.\n",
    "# - y_val is the ground-truth label (0/1).\n",
    "# - meta_val has the user_id information.\n",
    "\n",
    "# Generate predicted scores for the validation set\n",
    "pred_scores = model.predict(X_val[feats], num_iteration=model.best_iteration)\n",
    "\n",
    "# Combine back into a DataFrame for easy groupby\n",
    "val_df = X_val.copy()\n",
    "val_df['pred_score'] = pred_scores\n",
    "val_df['label'] = y_val.values\n",
    "val_df['user_id'] = meta_val['user_id'].values\n",
    "\n",
    "ndcg_list = []\n",
    "\n",
    "for user_id, group in val_df.groupby('user_id'):\n",
    "    if len(group) < 2:\n",
    "        continue  # skip users with only 1 product\n",
    "\n",
    "    true_relevance = group['label'].values.reshape(1, -1)\n",
    "    scores = group['pred_score'].values.reshape(1, -1)\n",
    "    \n",
    "    if true_relevance.sum() > 0:\n",
    "        ndcg = ndcg_score(true_relevance, scores, k=10)\n",
    "        ndcg_list.append(ndcg)\n",
    "\n",
    "mean_ndcg = np.mean(ndcg_list)\n",
    "print(f\"Mean NDCG@10: {mean_ndcg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "257f5612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "X_val['label'] = train_df['label'].values      \n",
    "# Group back predictions by user\n",
    "for user_id, group in X_val.groupby('user_id'):\n",
    "    true_relevance = group['label'].values\n",
    "    scores = group['pred_score'].values\n",
    "    ndcg = ndcg_score([true_relevance], [scores], k=10)\n",
    "    # store or print ndcg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "056959c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.907613572455749\n"
     ]
    }
   ],
   "source": [
    "print(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312e0d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users with invalid label variety: 0\n"
     ]
    }
   ],
   "source": [
    "label_counts = training_df.groupby('user_id')['label'].nunique()\n",
    "invalid_users = label_counts[label_counts < 2]\n",
    "print(f\"Users with invalid label variety: {len(invalid_users)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f6ef821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    0.681762\n",
       "0    0.318238\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts(normalize=True) # nos aseguramos de que sea balanceado el data set\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
